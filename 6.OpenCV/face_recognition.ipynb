{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ed9046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from opencv-python) (2.2.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fe9399f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dlib in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (20.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab7b00f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytesseract\n",
      "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from pytesseract) (11.3.0)\n",
      "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: pytesseract\n",
      "Successfully installed pytesseract-0.3.13\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a72822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (80.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cca85fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import face_recognition\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91aedb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a different person\n"
     ]
    }
   ],
   "source": [
    "# known_Image\n",
    "image1=face_recognition.load_image_file(\"data/person1.jpg\")\n",
    "encoding1=face_recognition.face_encodings(image1)[0]\n",
    "\n",
    "#Unknown_Image\n",
    "image2=face_recognition.load_image_file(\"data/person2.jpeg\") \n",
    "encoding2=face_recognition.face_encodings(image2)[0]\n",
    "\n",
    "result=face_recognition.compare_faces([encoding1],encoding2)\n",
    "\n",
    "if result[0]:\n",
    "    print(\"It is the same person\")\n",
    "else:\n",
    "    print(\"It is a different person\")\n",
    "\n",
    "cv2.imshow(\"compared images1\",image1)\n",
    "cv2.imshow(\"compared images2\",image2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae5f64",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">1.Face_Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31feb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "img=cv2.imread(\"data/Baby-pic2.jpg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"Faces\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863021d0",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">2.Eye_Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e35d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "img=cv2.imread(\"data/kutty1.jpeg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,200,0),2)\n",
    "\n",
    "cv2.imshow(\"Eyes\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4f8bb",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">3.Eye_tree_eyeglasses_Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca21254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye_tree_eyeglasses.xml')\n",
    "\n",
    "img=cv2.imread(\"data/baby-pic3.jpg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5)\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "cv2.imshow(\"Eyes\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bdc247c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import dlib\n",
    "import pkg_resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64309255",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">Face_Recognition</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cca1167",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">1.Load an Image</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601e28dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=face_recognition.load_image_file(\"data/Baby-Pic1.jpeg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e41f35",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">2.Find Face Location</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41db8d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 face(s)\n",
      "[(348, 656, 811, 194)]\n"
     ]
    }
   ],
   "source": [
    "face_locations=face_recognition.face_locations(image)\n",
    "\n",
    "print(\"Found\",len(face_locations),\"face(s)\")\n",
    "print(face_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0cb04",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">3.Face_Encoding</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7111b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of encoding 1\n",
      "[-9.93974879e-02  1.40824188e-02  4.48355265e-02 -1.27432510e-01\n",
      " -1.44525170e-01  6.27530180e-03 -2.01392733e-03 -3.01006865e-02\n",
      "  2.02905446e-01 -1.23536184e-01  1.50234789e-01 -2.85916422e-02\n",
      " -1.35112613e-01  6.75595626e-02 -8.37135501e-03  1.89087480e-01\n",
      " -1.53347909e-01 -1.38014168e-01 -6.83928654e-02 -3.37162875e-02\n",
      "  5.16344886e-03  8.94816369e-02 -1.13840118e-01  1.48821428e-01\n",
      " -1.31151915e-01 -3.45480174e-01 -2.76449732e-02 -7.91897476e-02\n",
      " -9.14475620e-02 -3.16494144e-02  4.21403013e-02  1.17877416e-01\n",
      " -1.97685227e-01 -3.58179845e-02  4.81087640e-02  6.32742196e-02\n",
      " -8.20229128e-02 -1.46185338e-01  2.24062622e-01  9.27438363e-02\n",
      " -2.30436429e-01 -2.92604081e-02  1.29735723e-01  2.93444127e-01\n",
      "  1.29310995e-01 -7.35457763e-02 -5.14479540e-03 -2.33110934e-02\n",
      "  1.42508954e-01 -2.96330720e-01 -5.99591434e-02  1.31314427e-01\n",
      "  3.25883701e-02  5.01207933e-02  9.71308276e-02 -7.78108761e-02\n",
      "  1.03572622e-01  6.47100732e-02 -2.20607802e-01  3.10651641e-02\n",
      "  4.12877947e-02 -1.19451478e-01 -1.20438002e-02 -1.15734473e-01\n",
      "  2.64400125e-01  7.97518790e-02 -9.80291143e-02 -9.56872776e-02\n",
      "  1.21672742e-01 -1.08351842e-01 -1.16710082e-01  1.03599578e-02\n",
      " -1.15523495e-01 -1.90617964e-01 -3.10058415e-01  1.73521135e-02\n",
      "  4.02658433e-01  1.41049370e-01 -1.73665926e-01  9.70413238e-02\n",
      " -3.76585014e-02 -8.20330903e-02  1.03357583e-01  1.51446342e-01\n",
      "  3.55279446e-02 -3.88222151e-02 -1.56567246e-03  6.92356005e-02\n",
      "  2.62913704e-01  3.82319540e-02  9.41122137e-03  2.12748334e-01\n",
      " -2.23454274e-03 -6.52591959e-02  4.85604629e-03  2.31612418e-02\n",
      " -1.05457090e-01 -1.45556498e-03 -1.33232489e-01  4.33377326e-02\n",
      "  1.86617710e-02 -6.61215000e-03  1.91903375e-02  1.60040796e-01\n",
      " -2.68323094e-01  1.29942700e-01  2.63982220e-04 -9.28030014e-02\n",
      "  1.78655982e-02  2.72257570e-02 -1.60694033e-01 -3.74391899e-02\n",
      "  1.18457526e-01 -2.04787552e-01  1.34226263e-01  9.79742706e-02\n",
      "  1.75604802e-02  1.16621986e-01  4.20112684e-02  3.89399938e-04\n",
      " -3.23581323e-02 -5.83882257e-03 -2.07619846e-01 -7.03644156e-02\n",
      "  9.50661525e-02 -2.84191817e-02  4.94935736e-02  1.51271243e-02]\n"
     ]
    }
   ],
   "source": [
    "face_encoding=face_recognition.face_encodings(image)\n",
    "\n",
    "print(\"Number of encoding\",len(face_encoding))\n",
    "print(face_encoding[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a87265f",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">4.Compare_Face</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "818ac36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is same person False\n"
     ]
    }
   ],
   "source": [
    "known_image=face_recognition.load_image_file(\"data/person1.jpg\")\n",
    "unknown_image=face_recognition.load_image_file(\"data/baby-pic3.jpg\")\n",
    "\n",
    "known_encoding=face_recognition.face_encodings(known_image)[0]\n",
    "unknown_encoding=face_recognition.face_encodings(unknown_image)[0]\n",
    "\n",
    "results=face_recognition.compare_faces([known_encoding],unknown_encoding)\n",
    "print('Is same person',results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609d3f12",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">5.Face_Distance(similarity Score)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e292ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face Distance: [0.81979766]\n"
     ]
    }
   ],
   "source": [
    "from face_recognition import face_distance\n",
    "\n",
    "dist=face_distance([known_encoding],unknown_encoding)\n",
    "print(\"Face Distance:\",dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f7139",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">6.Real-Time Face Recognition with Webcam</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c7b2675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import tkinter as tk\n",
    "from tkinter import Label,BOTTOM\n",
    "from PIL import Image,ImageTk\n",
    "import os\n",
    "\n",
    "cap = cv2.VideoCapture(0) #ithu camera open pandrathukkana library\n",
    "\n",
    "img_counter = 0  # photo save pandrathukku use pannuvom\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  #ret-capture successfully, frame-Actual image, cap.read()-read the next frame from the camera\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if key == ord('c'):  # 'c' press panna capture aagum\n",
    "        img_name = f\"photo_{img_counter}.png\"\n",
    "        cv2.imwrite(img_name, frame)\n",
    "        print(f\"{img_name} saved!\")\n",
    "        img_counter += 1\n",
    "\n",
    "    elif key == ord('q'): #'q' press panna close aagum\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734458f0",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">Single_Person Face_Recognition + Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99339552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# Known images\n",
    "known_image = face_recognition.load_image_file(\"data/kutty1.jpeg\")\n",
    "known_encoding = face_recognition.face_encodings(known_image)[0]\n",
    "\n",
    "# list la store panrom\n",
    "known_encodings = [known_encoding]\n",
    "known_names = [\"This is JOHN\"]\n",
    "\n",
    "# Step 2: Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Resize for speed\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Step 3: Detect faces\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "    \n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        name = \"Unknown Person\"\n",
    "        \n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_names[first_match_index]\n",
    "        \n",
    "        # Scale back (4x because we reduced image size earlier)\n",
    "        top, right, bottom, left = top*4, right*4, bottom*4, left*4\n",
    "        \n",
    "        # Draw box + name\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    \n",
    "    cv2.imshow(\"Face Recognition\", frame)\n",
    "    \n",
    "    # press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356236b2",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">Explain above program</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "397a8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# step 1: Known images\n",
    "known_image = face_recognition.load_image_file(\"data/id_card.jpeg\")  # Oru photo a load pandrom\n",
    "known_encoding = face_recognition.face_encodings(known_image)[0]  # Antha photo la irukkura face a detect pannittu atha oru object la save pandrom\n",
    "                                                                  # [0]- ithu ethukkuna naama load pandra image la niraiya photo irukkalam aana athula ethu first irukko antha face a eduththukkum    \n",
    "\n",
    "# list la store panrom\n",
    "known_encodings = [known_encoding] #known encoding a array va maththi oru object la save pandrom\n",
    "known_names = [\"Person 1\"]  # naama kuduththa image kku name set pandrom\n",
    "\n",
    "# Step 2: Open camera\n",
    "cap = cv2.VideoCapture(0)   # Laptop camera va open pandrathukkana function\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()   #  Camera la oru image a read pannuthu , ret-Capture successfully\n",
    "    if not ret: #  ret false aa iruntha\n",
    "        break  # loop break aaidum\n",
    "    \n",
    "    # Resize for speed\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)  # Frame size a 25% kku reduce pandrom->appothan speed aa improve aagum\n",
    "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)  #openCV ooda default color BGR than aana face_recognition RGB than expect pannum athanala BGR la irunthu RGB kku convert pandrom\n",
    "    \n",
    "    # Step 3: Detect faces\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)  # Detect panna face kku coordinates kudukkum athavathu (top,right,bottom,left)nu \n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)  # Detect panna facekku encoding vector a generate pannum\n",
    "    \n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings): # ella face oda locationsaium thirumba thirumba encoding pannum  \n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)  #  Naama input aa kuduththa image encoding oda live face ium compare pannum\n",
    "        name = \"Unknown\" # Live image oda match aagalaina \"Unknown\" ngura default name a show pannum\n",
    "        \n",
    "        if True in matches:  # compare panna image True aa iruntha \n",
    "            first_match_index = matches.index(True)  # Index eduththu 'known_names' la correct aana name('person 1') a fetch pannum \n",
    "            name = known_names[first_match_index]\n",
    "        \n",
    "        # Scale back (4x because we reduced image size earlier)\n",
    "        top, right, bottom, left = top*4, right*4, bottom*4, left*4  # Naama already 25% resize pannom ippo original frame kku 4x aa scale back pandrom\n",
    "        \n",
    "        # Draw box + name\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2) # rectangle - face kku green box a draw pannum \n",
    "        cv2.putText(frame, name, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)  # PutText - Box mela name a print pannum\n",
    "    \n",
    "    cv2.imshow(\"Face Recognition\", frame)  # Window a open pannittu live frame a show pannum\n",
    "    \n",
    "    # press 'q' to quit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # waitkey - naama keyboard la ethavathu key a press pandromanu check pannum\n",
    "        break   # \"q\" key a press panna loop break aagi program a exit pannidum\n",
    "\n",
    "cap.release() # Camera close aaidum\n",
    "cv2.destroyAllWindows() # OpenCV windows mm  close aaidum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c53a9ca",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">Multiple_Person Face_Recognition + Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a66e92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "\n",
    "# Step 1: Load known faces\n",
    "known_encodings = []\n",
    "known_names = []\n",
    "\n",
    "# Person 1\n",
    "image1 = face_recognition.load_image_file(\"data/johnson.jpeg\")\n",
    "known_encodings.append(face_recognition.face_encodings(image1)[0])\n",
    "known_names.append(\"Person 1\")\n",
    "\n",
    "# Person 2\n",
    "image2 = face_recognition.load_image_file(\"data/jai.jpeg\")\n",
    "known_encodings.append(face_recognition.face_encodings(image2)[0])\n",
    "known_names.append(\"Person 2\")\n",
    "\n",
    "# Person 3\n",
    "image3 = face_recognition.load_image_file(\"data/kutty1.jpeg\")\n",
    "known_encodings.append(face_recognition.face_encodings(image3)[0])\n",
    "known_names.append(\"Person 3\")\n",
    "\n",
    "# Step 2: Open camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize for speed\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Detect faces\n",
    "    face_locations = face_recognition.face_locations(rgb_small_frame)\n",
    "    face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # Compare with known faces\n",
    "        matches = face_recognition.compare_faces(known_encodings, face_encoding)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_names[first_match_index]\n",
    "\n",
    "        # Scale back to original frame size\n",
    "        top, right, bottom, left = top*4, right*4, bottom*4, left*4\n",
    "\n",
    "        # Draw rectangle + name\n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, name, (left, top-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"Multiple Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba510f15",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:20px;\">Smart_Attendance(Face_recognition) with explain</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c318d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                      #Camera open panna and rectangle draw panna)\n",
    "import face_recognition         #Face detect panna and encode panna use pandra library\n",
    "import os                       #Folder la irukkura file a list aa mathurathukku use pandra library\n",
    "import numpy as np              #Distance kandupudikka and array handling panna use pandra library \n",
    "from datetime import datetime   #Current time a eduththukurathukkana library\n",
    "\n",
    "# Step 1: Folder path (students images)\n",
    "path = \"Students1\"  #Students oda image irukkura folder path\n",
    "images = []         #Ithu students oda image a store pandrathukkana oru empty list \n",
    "names = []          #Ithu students oda name a store pandrathukkana oru empty list\n",
    "\n",
    "# Step 2: Load student images\n",
    "student_files = os.listdir(path)            #Ithu folder la irukkura ella file-laium names list pannum \n",
    "for file in student_files:                  #Student_files a file nu oru variable a store pandrom\n",
    "    img = cv2.imread(f\"{path}/{file}\")      #Antha path la irukkura image a read pannum\n",
    "    images.append(img)                      #ithu image a list la add pannum\n",
    "    names.append(os.path.splitext(file)[0]) #Ithu file_name la irukkura .jpg/.png remove pannittu athula irukkura name a mattum eduthukkum\n",
    "\n",
    "# Step 3: Encode all student images\n",
    "def encode_images(images):                              #Ithu oru function, ithu image list eduthu encoding a generate pannum\n",
    "    encoding_list = []                                  #Ithu encoding panna image a list aa mathum\n",
    "    for img in images:                                  #images a img nu oru variable a store pandrom\n",
    "        rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)      #openCV BGR la irukkum, aana face recognition kku RGB than thevai so bgr la irunthu rgb kku convert pandrom\n",
    "        enc = face_recognition.face_encodings(rgb)[0]   #Ithu Fece encoding a generate pannum,\"[0]\"-ithu oru face irukkunu assume pannittu first irukkura face a eduththukkum\n",
    "        encoding_list.append(enc)                       #ithu image a encode panni list la add pannum\n",
    "    return encoding_list                                #Antha encoding list a return pandrom\n",
    "\n",
    "known_encodings = encode_images(images)                 #encode panna ella image mm student encodings la store aagum\n",
    "\n",
    "# Step 4: Attendance function\n",
    "def mark_attendance(name):                              #Attendance a mark pandra function\n",
    "    with open(\"Attendance.csv\", \"r+\") as f:             #Ithu attendance.csv file a open pannum\n",
    "        data = f.readlines()                        \n",
    "        name_list = []                                  #Already file a irukkura names a cheak pannum\n",
    "        for line in data:\n",
    "            entry = line.split(\",\")\n",
    "            name_list.append(entry[0])\n",
    "        if name not in name_list:\n",
    "            now = datetime.now()\n",
    "            time_str = now.strftime(\"%H:%M:%S\")         #New name a encounter panna, current time (HH:MM:SS) koda appand pannum \n",
    "            f.writelines(f\"\\n{name},{time_str}\")\n",
    "\n",
    "# Step 5: Start webcam for recognition\n",
    "cap = cv2.VideoCapture(0)      #ithu Laptop la irukkura camera a va open pannum                                 \n",
    "\n",
    "while True:                    #Ithu loop continuously camera la capture panna use aagum \n",
    "    success, frame = cap.read()#\"success\"-intha statement True aa illa False aa nu check pannum, \"frame\"- image a read pandrathukku use aagum\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)                      #Read panna image a RGB aa convert pannum\n",
    "\n",
    "    face_locations = face_recognition.face_locations(rgb_frame)             #frame la face a detect pannum(Coordinates a return pannum)\n",
    "    encodings = face_recognition.face_encodings(rgb_frame, face_locations)  #Detect panna face kku encoding generate pannum\n",
    "\n",
    "    for enc, loc in zip(encodings, face_locations):                         #Detect panna face a encode pannum, apram location a handle pannum\n",
    "        matches = face_recognition.compare_faces(known_encodings, enc)      #Detect panna face a path la irukkura face oda match panna try pannum\n",
    "        face_dist = face_recognition.face_distance(known_encodings, enc)    #Similarity distance a calculate pannum\n",
    "\n",
    "        best_match = np.argmin(face_dist)                                   #Distance la minimum value irukkura index a kandupudikkum\n",
    "        if matches[best_match]:\n",
    "            name = names[best_match].upper()                                #match aana student name a eduthukkum\n",
    "            y1, x2, y2, x1 = loc\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)          #Detect panna face kku rectangle draw pannum\n",
    "            cv2.putText(frame, name, (x1, y1-10),                       \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)        #Ithu name a face mela print pannum\n",
    "            mark_attendance(name)                                           #information a attendance file a mark pannum\n",
    "\n",
    "    cv2.imshow(\"Attendance System\", frame)  #Attendance System nu window la live video show pannum\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):   #User 'q' a press panna loop break aagum, program stop aagum\n",
    "        break\n",
    "\n",
    "cap.release()           #Camera close aagum\n",
    "cv2.destroyAllWindows() #openCV windows mm close aagum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a3f85",
   "metadata": {},
   "source": [
    "<span style= \"color:red; font-size:20px;\">Car Number Plate Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "689f8998",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "plate_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_russian_plate_number.xml\")\n",
    "\n",
    "img = cv2.imread(\"data/car.jpeg\")   # <-- unga car image filename\n",
    "small=cv2.resize(img,(500,500))\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "plates = plate_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "for (x,y,w,h) in plates:\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0.255,0), 2)\n",
    "    cv2.putText(img, \"Number Plate\", (x, y - 10),cv2.FONT_HERSHEY_SIMPLEX,0.9,(255,255,255), 2)\n",
    "\n",
    "    plate_region =img[y:y + h, x:x + w]\n",
    "    cv2.imshow(\"plate Region\", plate_region)\n",
    "    cv2.imshow(\"Car plate number Detection\", small)\n",
    "        \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a290c7d0",
   "metadata": {},
   "source": [
    "<span style= \"color:red; font-size:20px;\">Face Expression Detection</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a48921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yolo\n",
      "  Downloading yolo-0.3.2-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting awscli (from yolo)\n",
      "  Downloading awscli-1.42.40-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting boto3 (from yolo)\n",
      "  Downloading boto3-1.40.40-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting botocore>=1.7.18 (from yolo)\n",
      "  Downloading botocore-1.40.40-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: click in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from yolo) (8.3.0)\n",
      "Collecting docker==3.4.0 (from yolo)\n",
      "  Downloading docker-3.4.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from yolo) (3.1.6)\n",
      "Collecting keyring==8.7.0 (from yolo)\n",
      "  Downloading keyring-8.7-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting keyrings.alt (from yolo)\n",
      "  Downloading keyrings.alt-5.0.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from yolo) (2.32.5)\n",
      "Collecting ruamel.yaml (from yolo)\n",
      "  Downloading ruamel.yaml-0.18.15-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tabulate in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from yolo) (0.9.0)\n",
      "Collecting voluptuous (from yolo)\n",
      "  Downloading voluptuous-0.15.2-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from docker==3.4.0->yolo) (1.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from docker==3.4.0->yolo) (1.8.0)\n",
      "Collecting docker-pycreds>=0.3.0 (from docker==3.4.0->yolo)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of docker to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting yolo\n",
      "  Downloading yolo-0.3.1.tar.gz (44 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting docker (from yolo)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from docker->yolo) (311)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from docker->yolo) (2.5.0)\n",
      "Collecting pywin32-ctypes (from keyring==8.7.0->yolo)\n",
      "  Downloading pywin32_ctypes-0.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from botocore>=1.7.18->yolo)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from botocore>=1.7.18->yolo) (2.9.0.post0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from requests->yolo) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from requests->yolo) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from requests->yolo) (2025.8.3)\n",
      "Collecting docutils<=0.19,>=0.18.1 (from awscli->yolo)\n",
      "  Downloading docutils-0.19-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting s3transfer<0.15.0,>=0.14.0 (from awscli->yolo)\n",
      "  Downloading s3transfer-0.14.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=3.10 in c:\\users\\johnson\\.conda\\envs\\ds\\lib\\site-packages (from awscli->yolo) (6.0.2)\n",
      "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from awscli->yolo) (0.4.6)\n",
      "Collecting rsa<4.8,>=3.1.2 (from awscli->yolo)\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.8,>=3.1.2->awscli->yolo)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\johnson\\appdata\\roaming\\python\\python313\\site-packages (from jinja2->yolo) (3.0.3)\n",
      "Collecting jaraco.classes (from keyrings.alt->yolo)\n",
      "  Downloading jaraco.classes-3.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting jaraco.context (from keyrings.alt->yolo)\n",
      "  Downloading jaraco.context-6.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting more-itertools (from jaraco.classes->keyrings.alt->yolo)\n",
      "  Downloading more_itertools-10.8.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml->yolo)\n",
      "  Downloading ruamel.yaml.clib-0.2.14-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Downloading keyring-8.7-py2.py3-none-any.whl (33 kB)\n",
      "Downloading botocore-1.40.40-py3-none-any.whl (14.0 MB)\n",
      "   ---------------------------------------- 0.0/14.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/14.0 MB 3.0 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.0/14.0 MB 2.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.8/14.0 MB 3.0 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 2.6/14.0 MB 3.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 3.4/14.0 MB 3.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 4.2/14.0 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 5.0/14.0 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 6.0/14.0 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 6.8/14.0 MB 3.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 7.3/14.0 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.1/14.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 8.9/14.0 MB 3.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 10.0/14.0 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 11.0/14.0 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.3/14.0 MB 4.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.6/14.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.0/14.0 MB 4.2 MB/s  0:00:03\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading awscli-1.42.40-py3-none-any.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 1.0/4.7 MB 5.6 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.7 MB 6.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.9/4.7 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 6.6 MB/s  0:00:00\n",
      "Downloading docutils-0.19-py3-none-any.whl (570 kB)\n",
      "   ---------------------------------------- 0.0/570.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 570.5/570.5 kB 5.8 MB/s  0:00:00\n",
      "Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Downloading s3transfer-0.14.0-py3-none-any.whl (85 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Downloading boto3-1.40.40-py3-none-any.whl (139 kB)\n",
      "Downloading keyrings.alt-5.0.2-py3-none-any.whl (17 kB)\n",
      "Downloading jaraco.classes-3.4.0-py3-none-any.whl (6.8 kB)\n",
      "Downloading jaraco.context-6.0.1-py3-none-any.whl (6.8 kB)\n",
      "Downloading more_itertools-10.8.0-py3-none-any.whl (69 kB)\n",
      "Downloading pywin32_ctypes-0.2.3-py3-none-any.whl (30 kB)\n",
      "Downloading ruamel.yaml-0.18.15-py3-none-any.whl (119 kB)\n",
      "Downloading ruamel.yaml.clib-0.2.14-cp313-cp313-win_amd64.whl (115 kB)\n",
      "Downloading voluptuous-0.15.2-py3-none-any.whl (31 kB)\n",
      "Building wheels for collected packages: yolo\n",
      "  Building wheel for yolo (setup.py): started\n",
      "  Building wheel for yolo (setup.py): finished with status 'done'\n",
      "  Created wheel for yolo: filename=yolo-0.3.1-py3-none-any.whl size=51898 sha256=fb53c52fb5053707440df15ae47c067f25fff680e4ea548b8490ee29275c3534\n",
      "  Stored in directory: c:\\users\\johnson\\appdata\\local\\pip\\cache\\wheels\\db\\24\\e0\\9ed342aa8213b9100e2105ea2550c4b62cac6152eb9126c7fa\n",
      "Successfully built yolo\n",
      "Installing collected packages: voluptuous, ruamel.yaml.clib, pywin32-ctypes, pyasn1, more-itertools, jmespath, jaraco.context, docutils, ruamel.yaml, rsa, keyring, jaraco.classes, docker, botocore, s3transfer, keyrings.alt, boto3, awscli, yolo\n",
      "\n",
      "   ------ ---------------------------------  3/19 [pyasn1]\n",
      "   -------- -------------------------------  4/19 [more-itertools]\n",
      "   -------------- -------------------------  7/19 [docutils]\n",
      "   -------------- -------------------------  7/19 [docutils]\n",
      "   -------------- -------------------------  7/19 [docutils]\n",
      "   -------------- -------------------------  7/19 [docutils]\n",
      "   ---------------- -----------------------  8/19 [ruamel.yaml]\n",
      "   ------------------ ---------------------  9/19 [rsa]\n",
      "   ------------------------- -------------- 12/19 [docker]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   --------------------------- ------------ 13/19 [botocore]\n",
      "   ----------------------------- ---------- 14/19 [s3transfer]\n",
      "   --------------------------------- ------ 16/19 [boto3]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ----------------------------------- ---- 17/19 [awscli]\n",
      "   ---------------------------------------- 19/19 [yolo]\n",
      "\n",
      "Successfully installed awscli-1.42.40 boto3-1.40.40 botocore-1.40.40 docker-7.1.0 docutils-0.19 jaraco.classes-3.4.0 jaraco.context-6.0.1 jmespath-1.0.1 keyring-8.7 keyrings.alt-5.0.2 more-itertools-10.8.0 pyasn1-0.6.1 pywin32-ctypes-0.2.3 rsa-4.7.2 ruamel.yaml-0.18.15 ruamel.yaml.clib-0.2.14 s3transfer-0.14.0 voluptuous-0.15.2 yolo-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'yolo' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'yolo'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n"
     ]
    }
   ],
   "source": [
    "%pip install yolo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
